import os
import shutil
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Tuple

from mido import Message, MetaMessage, MidiFile, MidiTrack

from mappings import (
    BLUE_CYMBALS, BLUE_TOMS, DRUM_MAPPING, GREEN_CYMBALS,
    GREEN_TOMS, IS_TOM, KICK_NOTES, PRIORITY_MAP, SPLASH_NOTE,
    TOM_MARKERS_MAP,
    DRUM_BLUE, DRUM_GREEN, DRUM_YELLOW,
    GEM_GREEN, GEM_RED, GEM_YELLOW, GEM_BLUE, GEM_ORANGE,
    PROG_BASS_MIN, PROG_BASS_MAX, PROG_GUITAR_MIN, PROG_GUITAR_MAX
)


# Config
NOTE_LEN = 1
MIN_VELOCITY = 40 # Notes below this are considered ghosts/noise unless ghosts are enabled



class MidiToYARGConverter:
    """
    Handles the conversion of raw MIDI files into YARG/Clone Hero compatible charts.
    Includes logic for tempo mapping, beat generation, and strict limb-limit humanization.
    """

    def scan_tracks(self, midi_path: str) -> List[str]:
        """
        Scans the MIDI file and returns a list of track names prefixed with their index.
        """
        try:
            mid = MidiFile(midi_path)
            track_names = []
            for i, track in enumerate(mid.tracks):
                name = "Untitled Track"
                for msg in track:
                    if msg.type == "track_name":
                        name = msg.name
                        break
                track_names.append(f"{i}: {name}")
            return track_names
        except Exception:
            return []

    def process_song(self, midi_path: str, metadata: Dict[str, Any], output_dir: str, 
                     quantize: bool = True, include_ghosts: bool = False,
                     bass_idx: int = -1, guitar_idx: int = -1,
                     audio_path: str = "") -> str:
        """
        Main pipeline entry point. Prepares directories and orchestrates track generation.
        """
        out_path = Path(output_dir)
        
        # Clean folder name
        artist = self._clean_name(metadata.get("artist", "Unknown"))
        song = self._clean_name(metadata.get("name", "Untitled"))
        folder = out_path / f"{artist} - {song}"

        # Merging logic: Do NOT wipe folder. Just ensure it exists.
        folder.mkdir(parents=True, exist_ok=True)
        
        # Handle Audio File
        if audio_path and os.path.exists(audio_path):
            try:
                dest = folder / "song.ogg"
                shutil.copy2(audio_path, dest)
            except Exception as e:
                print(f"Error copying audio file: {e}")

        # Check explicit disables from metadata (-1)
        disable_drums = metadata.get('diff_drums') == "-1"
        disable_guitar = metadata.get('diff_guitar') == "-1"
        disable_bass = metadata.get('diff_bass') == "-1"

        # Core generation
        has_drums, has_bass, has_guitar = self._create_chart(
            midi_path, str(folder / "notes.mid"), quantize, include_ghosts, 
            bass_idx, guitar_idx,
            disable_drums, disable_guitar, disable_bass
        )
        self._create_ini(metadata, folder, has_drums, has_bass, has_guitar)

        return str(folder)

    def _clean_name(self, text: str) -> str:
        return "".join(c for c in text if c.isalnum() or c in " -_.").strip()

    def _create_ini(self, meta: Dict[str, Any], folder: Path, has_drums: bool = False, has_bass: bool = False, has_guitar: bool = False) -> None:
        lines = [
            "[song]",
            f"name = {meta.get('name', 'Unknown')}",
            f"artist = {meta.get('artist', 'Unknown')}",
            f"album = {meta.get('album', 'Unknown')}",
            f"genre = {meta.get('genre', 'Rock')}",
            f"year = {meta.get('year', '2025')}",
            f"diff_drums = {meta.get('diff_drums', '-1') if has_drums else '-1'}",
            "pro_drums = True",
            f"diff_band = {meta.get('diff_band', '-1')}",
            f"diff_guitar = {meta.get('diff_guitar', '-1') if has_guitar else '-1'}",
            f"diff_bass = {meta.get('diff_bass', '-1') if has_bass else '-1'}",
            "charter = Midi to YARG Converter",
            "loading_phrase = Auto-generated by the Midi to YARG Converter",
        ]
        (folder / "song.ini").write_text("\n".join(lines), encoding="utf-8")


    def _create_chart(self, input_path: str, output_path: str, quantize: bool, include_ghosts: bool,
                      bass_idx_override: int = -1, guitar_idx_override: int = -1,
                      disable_drums: bool = False, disable_guitar: bool = False, disable_bass: bool = False) -> Tuple[bool, bool, bool]:
        """
        Rebuilds the MIDI structure. Uses Type 1 to allow separate Tempo and Instrument tracks.
        Returns (has_drums, has_bass, has_guitar)
        """
        mid_in = MidiFile(input_path)
        mid_out = MidiFile(type=1, ticks_per_beat=mid_in.ticks_per_beat)

        # 1. Build Tempo Map (Track 0)
        tempo_events = self._build_tempo_track(mid_in, mid_out)

        # Calculate total song duration in ticks for the Beat Track
        total_ticks = max((sum(m.time for m in t) for t in mid_in.tracks), default=0)

        # 2. Generate Beat Track (Visual grid/metronome)
        self._create_beat_track(mid_out, total_ticks, mid_in.ticks_per_beat, tempo_events)

        # 3. Build Drums Track (Conditional)
        has_drums = False
        if not disable_drums:
            drum_events = self._process_drums(mid_in, quantize)
            
            if drum_events:
                has_drums = True
                drum_track = MidiTrack()
                mid_out.tracks.append(drum_track)
                
                # Standard YARG/CH track headers for Drums
                for h in ["PART DRUMS", "[mix 0 drums0]", "[play]", "[music_start]"]:
                    type_ = "track_name" if "PART" in h else "text"
                    kw = "name" if "PART" in h else "text"
                    drum_track.append(MetaMessage(type_, **{kw: h}, time=0))

                self._write_track(drum_track, drum_events)

        # 4. Instrument Selection (Manual Override vs Auto-Detect)
        if not disable_bass:
            if bass_idx_override != -1:
                bass_idx = bass_idx_override
            else:
                bass_idx = self._find_track_index(mid_in, "bass", PROG_BASS_MIN, PROG_BASS_MAX)
        else:
            bass_idx = -1

        if not disable_guitar:
            if guitar_idx_override != -1:
                guitar_idx = guitar_idx_override
            else:
                guitar_idx = self._find_track_index(mid_in, "guitar", PROG_GUITAR_MIN, PROG_GUITAR_MAX)
        else:
            guitar_idx = -1

        # 5. Build Bass Track
        has_bass = False
        if bass_idx != -1 and not disable_bass:
            bass_track = MidiTrack()
            mid_out.tracks.append(bass_track)
            has_bass = True
            
            # Headers
            bass_track.append(MetaMessage("track_name", name="PART BASS", time=0))
            bass_track.append(MetaMessage("text", text="[play]", time=0))
            bass_track.append(MetaMessage("text", text="[music_start]", time=0))

            bass_events = self._process_5lane(mid_in.tracks[bass_idx], quantize, mid_in.ticks_per_beat, include_ghosts, tempo_events)
            self._write_track(bass_track, bass_events)

        # 6. Build Guitar Track
        has_guitar = False
        if guitar_idx != -1 and not disable_guitar:
            guitar_track = MidiTrack()
            mid_out.tracks.append(guitar_track)
            has_guitar = True
            
            # Headers
            guitar_track.append(MetaMessage("track_name", name="PART GUITAR", time=0))
            guitar_track.append(MetaMessage("text", text="[play]", time=0))
            guitar_track.append(MetaMessage("text", text="[music_start]", time=0))

            # Re-use logic for Guitar
            guitar_events = self._process_5lane(mid_in.tracks[guitar_idx], quantize, mid_in.ticks_per_beat, include_ghosts, tempo_events)
            self._write_track(guitar_track, guitar_events)

        mid_out.save(output_path)
        return has_drums, has_bass, has_guitar

    def _find_track_index(self, mid: MidiFile, name_keyword: str, prog_min: int, prog_max: int) -> int:
        """
        Helper to find track index by name or program change.
        """
        for i, track in enumerate(mid.tracks):
            for msg in track:
                if msg.type == "track_name" and name_keyword in msg.name.lower():
                    return i
                if msg.type == "program_change":
                    if prog_min <= msg.program <= prog_max:
                        return i
        return -1

    def _create_beat_track(self, mid: MidiFile, duration: int, ticks_per_beat: int, tempo_events: List[Tuple[int, MetaMessage]]) -> None:
        """
        Generates the 'BEAT' track used by the game engine for grid alignment.
        """
        track = MidiTrack()
        track.append(MetaMessage("track_name", name="BEAT", time=0))
        mid.tracks.append(track)

        # Default to 4/4 if no signature found
        sigs = [(0, 4)]
        for t, msg in tempo_events:
            if msg.type == "time_signature":
                sigs.append((t, msg.numerator))
        sigs.sort(key=lambda x: x[0])

        curr = 0
        last = 0
        idx = 0
        beats_bar = sigs[0][1]
        beat_count = 0

        # Iterate through every beat in the song
        while curr < duration:
            # Update time signature if we passed a change event
            if idx + 1 < len(sigs) and curr >= sigs[idx + 1][0]:
                idx += 1
                beats_bar = sigs[idx][1]
                beat_count = 0

            # MIDI Note 12 = Downbeat (Bar start), 13 = Standard beat
            note = 12 if beat_count == 0 else 13
            
            track.append(Message("note_on", note=note, velocity=100, time=curr - last, channel=0))
            track.append(Message("note_off", note=note, velocity=0, time=0, channel=0))

            last = curr
            curr += ticks_per_beat
            beat_count = (beat_count + 1) % beats_bar

    def _build_tempo_track(self, mid_in: MidiFile, mid_out: MidiFile) -> List[Tuple[int, MetaMessage]]:
        """
        Extracts tempo events and builds the Tempo Map track.
        """
        tempo_track = MidiTrack()
        tempo_track.name = "Tempo Map"
        mid_out.tracks.append(tempo_track)

        tempo_events = []
        abs_time = 0
        
        # Flatten track 0 events to absolute time
        for msg in mid_in.tracks[0]:
            abs_time += msg.time
            if msg.type in ("set_tempo", "time_signature"):
                tempo_events.append((abs_time, msg))

        # Write to track
        last_t = 0
        for t, msg in tempo_events:
            tempo_track.append(msg.copy(time=t - last_t))
            last_t = t
            
        return tempo_events

    def _process_drums(self, mid_in: MidiFile, quantize: bool) -> List[Tuple[int, str, int, int]]:
        """
        Orchestrates the drum processing pipeline: Quantize (Optional) -> Humanize -> Conflict Resolve.
        """
        if quantize:
            timeline = self._quantize_events(mid_in)
        else:
            timeline = self._get_raw_events(mid_in)
        self._humanize_timeline(timeline)
        return self._resolve_conflicts(timeline)

    def _quantize_events(self, mid_in: MidiFile) -> Dict[int, List[int]]:
        """
        Reads MIDI tracks and snaps notes to the nearest grid.
        """
        timeline = defaultdict(list)
        tpb = mid_in.ticks_per_beat
        
        # Config: Snap tolerance (11%)
        # Grid: 1/8 notes (Eighth notes) -> tpb / 2 
        # (Standard beat is 1/4 note, so half a beat is 1/8)
        tolerance_ticks = tpb * 0.11
        anchor_grid = tpb / 2

        for track in mid_in.tracks:
            abs_t = 0
            for msg in track:
                abs_t += msg.time
                if (msg.type == "note_on" and msg.channel == 9):
                    if msg.velocity >= MIN_VELOCITY and msg.note in DRUM_MAPPING:
                        # Grid snapping
                        nearest = round(abs_t / anchor_grid) * anchor_grid
                        final_time = int(nearest) if abs(abs_t - nearest) <= tolerance_ticks else abs_t
                        timeline[final_time].append(msg.note)
        return timeline

    def _get_raw_events(self, mid_in: MidiFile) -> Dict[int, List[int]]:
        """
        Reads MIDI tracks and extracts notes without snapping to grid.
        """
        timeline = defaultdict(list)
        
        for track in mid_in.tracks:
            abs_t = 0
            for msg in track:
                abs_t += msg.time
                if (msg.type == "note_on" and msg.channel == 9):
                    if msg.velocity >= MIN_VELOCITY and msg.note in DRUM_MAPPING:
                        timeline[abs_t].append(msg.note)
        return timeline

    def _resolve_conflicts(self, timeline: Dict[int, List[int]]) -> List[Tuple[int, str, int, int]]:
        """
        Converts timeline to events and resolves color collisions.
        Includes Double-Cymbal logic: 
        - Splash(Yellow) + HiHat(Yellow) -> Splash moves to Green
        - Blue Cymbal + Blue Cymbal -> Move one to Green
        - Green Cymbal + Green Cymbal -> Move one to Blue
        - Tom + Cymbal Collision -> Move Cymbal
        """
        final_events = []

        for t in sorted(timeline.keys()):
            raw_notes = set(timeline[t])
            
            # Temporary storage to track occupied colors for this timestamp
            notes_by_color = defaultdict(list)

            for midi_n in raw_notes:
                gem = DRUM_MAPPING[midi_n]
                
                # --- Special Splash Logic ---
                # If this is splash AND there is another yellow note (likely HH), move Splash to Green
                if midi_n == SPLASH_NOTE:
                    # check if any OTHER note maps to yellow
                    other_yellows = [n for n in raw_notes if n != SPLASH_NOTE and DRUM_MAPPING[n] == DRUM_YELLOW]
                    if other_yellows:
                        gem = DRUM_GREEN

                notes_by_color[gem].append(midi_n)
            
            # --- Double Cymbal Logic (Self-Collision) ---
            # If we have > 1 note mapping to Blue or Green, we might need to split them
            
            # Check Blue Cymbals Collision
            blue_cymbals = [n for n in raw_notes if n in BLUE_CYMBALS]
            if len(blue_cymbals) > 1:
                # We have 2+ blue cymbals (e.g. Ride + Crash2). Move the second one to Green.
                # Find which notes are mapped to Blue currently
                current_blues = notes_by_color[DRUM_BLUE]
                if len(current_blues) > 1:
                    # Move one of them (e.g. the last one found or specifically the crash)
                    # Simple heuristic: Move the one with higher pitch (Crash2=57 usually > Ride=51)
                    note_to_move = max(current_blues) 
                    
                    # Update mapping for this instance
                    # Remove from blue list
                    notes_by_color[DRUM_BLUE].remove(note_to_move)
                    # Add to Green (or check if green is full?)
                    # For now, force Green.
                    notes_by_color[DRUM_GREEN].append(note_to_move)

             # Check Green Cymbals Collision
            green_cymbals = [n for n in raw_notes if n in GREEN_CYMBALS]
            if len(green_cymbals) > 1:
                # 2+ Green Cymbals (Crash1 + China). Move one to Blue.
                current_greens = notes_by_color[DRUM_GREEN]
                if len(current_greens) > 1:
                    note_to_move = max(current_greens)
                    notes_by_color[DRUM_GREEN].remove(note_to_move)
                    notes_by_color[DRUM_BLUE].append(note_to_move)


            # --- Tom vs Cymbal Collision (Physical Impossibility) ---
            # Now we iterate through the FINAL proposed colors to check Tom/Cymbal clashes
            
            # Flatten dict to list of (midi, assigned_gem)
            final_assignments = []
            for gem, notes in notes_by_color.items():
                for n in notes:
                    final_assignments.append((n, gem))
            
            # Re-check Tom Collisions on the assigned gems
            assigned_gems_set = set(g for _, g in final_assignments)
            
            green_tom_present = not raw_notes.isdisjoint(GREEN_TOMS)
            blue_tom_present = not raw_notes.isdisjoint(BLUE_TOMS)
            
            start_gems = []
            for midi_n, gem in final_assignments:
                final_gem = gem
                
                # If we have a Cymbal on Green AND a Green Tom exists -> Move Cymbal to Blue
                if gem == DRUM_GREEN and midi_n in GREEN_CYMBALS and green_tom_present:
                     final_gem = DRUM_BLUE
                
                # If we have a Cymbal on Blue AND a Blue Tom exists -> Move Cymbal to Green
                if gem == DRUM_BLUE and midi_n in BLUE_CYMBALS and blue_tom_present:
                     final_gem = DRUM_GREEN
                     
                start_gems.append(final_gem)

            # --- Final Unique Filter ---
            # Prevent writing same gem twice (e.g. if logic moved everything to Green)
            unique_gems = sorted(list(set(start_gems)))
            
            for g in unique_gems:
                final_events.append((t, "note_on", g, 100))
                final_events.append((t + NOTE_LEN, "note_off", g, 0))
                
            # Re-loop for markers based on raw
            for midi_n in raw_notes:
                 if midi_n in IS_TOM:
                     # Check where this tom normally goes
                     natural_gem = DRUM_MAPPING[midi_n]
                     # If we outputted this gem, add marker
                     if natural_gem in unique_gems:
                         if natural_gem in TOM_MARKERS_MAP:
                             marker = TOM_MARKERS_MAP[natural_gem]
                             final_events.append((t, "note_on", marker, 100))
                             final_events.append((t + NOTE_LEN, "note_off", marker, 0))

        return sorted(final_events, key=lambda x: x[0])



    def _humanize_timeline(self, timeline: Dict[int, List[int]]) -> None:
        """
        Enforces 2-hand limit. Kicks are ignored (feet).
        Priority: Snare/Crash (3) > Tom/Ride (2) > Hi-Hat (1).
        """
        for t, notes in timeline.items():
            unique_notes = list(set(notes))
            
            # No optimization needed for feasible hits
            if len(unique_notes) <= 2:
                continue

            hands = [n for n in unique_notes if n not in KICK_NOTES]
            feet = [n for n in unique_notes if n in KICK_NOTES]

            if len(hands) > 2:
                # Sort descending: highest priority remains at index 0 and 1
                hands.sort(key=lambda x: PRIORITY_MAP.get(x, 2), reverse=True)
                
                # Keep top 2 hands + all feet
                timeline[t] = feet + hands[:2]

    def _process_5lane(self, track: MidiTrack, quantize: bool, tpb: int, include_ghosts: bool, tempo_events: List[Tuple[int, MetaMessage]]) -> List[Tuple[int, str, int, int]]:
        """
        Processes 5-lane instrument notes (Guitar/Bass) with Dynamic Anchor Windows.
        Adapts to Time Signature changes to define 4-bar chunks accurately.
        """
        # 1. Prepare Data: Filter valid notes
        parsed_notes = []
        active_notes = {} 
        abs_t = 0
        
        vel_threshold = 1 if include_ghosts else MIN_VELOCITY

        for msg in track:
            abs_t += msg.time
            if msg.type == "note_on" and msg.velocity > 0:
                active_notes[msg.note] = (abs_t, msg.velocity)
            elif (msg.type == "note_off") or (msg.type == "note_on" and msg.velocity == 0):
                if msg.note in active_notes:
                    start_t, velocity = active_notes.pop(msg.note)
                    if velocity >= vel_threshold:
                        duration = abs_t - start_t
                        if duration > 0:
                            parsed_notes.append((start_t, duration, msg.note))

        if not parsed_notes:
            return []

        # 2. Build Dynamic Windows (4 Bars per window based on Time Signature)
        # Sort TS events
        ts_events = [x for x in tempo_events if x[1].type == "time_signature"]
        ts_events.sort(key=lambda x: x[0])
        
        # Default 4/4 if no initial event
        if not ts_events or ts_events[0][0] > 0:
            ts_events.insert(0, (0, MetaMessage("time_signature", numerator=4, denominator=4)))

        # Determine last note time to know when to stop
        last_note_end = max(n[0] + n[1] for n in parsed_notes)
        
        windows = [] # [(start_tick, end_tick), ...]
        curr_t = 0
        ts_idx = 0
        
        # Generate windows covering the whole song duration
        while curr_t < last_note_end:
            # Check if we moved into a new TS zone
            if ts_idx + 1 < len(ts_events) and curr_t >= ts_events[ts_idx + 1][0]:
                ts_idx += 1
                curr_t = ts_events[ts_idx][0] # Snap to TS change

            msg = ts_events[ts_idx][1]
            # Calculate tick length of 4 bars
            # Ticks per Bar = tpb * (4 / denom) * numer
            # Standard MIDI: tpb is ticks per quarter note
            ticks_per_bar = int(tpb * 4 * msg.numerator / msg.denominator)
            window_len = ticks_per_bar * 4
            
            # Add windows until we hit next event or end
            next_event_t = ts_events[ts_idx + 1][0] if ts_idx + 1 < len(ts_events) else float('inf')
            
            while curr_t < next_event_t and curr_t < last_note_end:
                 effective_end = min(curr_t + window_len, next_event_t)
                 
                 if effective_end > curr_t:
                     windows.append((curr_t, effective_end))
                     curr_t += window_len
                 else:
                     curr_t = next_event_t

        # 3. Assign notes to windows
        windowed_notes = defaultdict(list)
        
        for p_note in parsed_notes:
            t_start = p_note[0]
            for i, (w_start, w_end) in enumerate(windows):
                if w_start <= t_start < w_end:
                    windowed_notes[i].append(p_note)
                    break
        
        # 4. Process
        anchor_grid = tpb / 2
        tolerance_ticks = tpb * 0.11
        events_buffer = []

        for w_idx in sorted(windowed_notes.keys()):
            notes_in_window = windowed_notes[w_idx]
            
            pitches = [n for _, _, n in notes_in_window]
            unique_pitches = sorted(list(set(pitches)))
            local_pitch_map = {note: i for i, note in enumerate(unique_pitches)}
            
            # Pre-calculate unique timestamps to find gaps between musical events/chords
            all_times = sorted(list(set(t for t, _, _ in notes_in_window)))
            time_map = {t: i for i, t in enumerate(all_times)}
            sorted_notes = sorted(notes_in_window, key=lambda x: x[0])

            for i, (t, dur, note) in enumerate(sorted_notes):
                final_time = t
                if quantize:
                    nearest = round(t / anchor_grid) * anchor_grid
                    if abs(t - nearest) <= tolerance_ticks:
                        final_time = int(nearest)

                rank = local_pitch_map[note]
                gem_offset = rank % 5
                gem = GEM_GREEN + gem_offset
                
                # --- Sustain Logic (Time-Based) ---
                # Fixed Visual Gap
                gap_ticks = 30  
                
                # Find current tempo (microseconds per beat) to convert ticks to ms
                current_mpqn = 500000 # Default 120 BPM
                for ev_t, ev_msg in tempo_events:
                    if ev_t > t:
                        break
                    if ev_msg.type == 'set_tempo':
                        current_mpqn = ev_msg.tempo
                
                # Convert duration to milliseconds
                # Formula: (ticks / tpb) * (microseconds_per_beat / 1000)
                dur_ms = (dur / tpb) * (current_mpqn / 1000.0)
                
                # Threshold for a "playable" sustain (approx 170-200ms)
                MIN_SUSTAIN_MS = 200.0 
                
                # Check 1: Is the note long enough?
                is_long_enough = dur_ms >= MIN_SUSTAIN_MS
                
                # Check 2: Space availability
                # We do NOT allow "sustained arpeggios". If another note starts while this one 
                # is holding (and it's not a chord), we cut the sustain.
                has_space = True
                if is_long_enough:
                     effective_end = t + dur - gap_ticks
                     # Look ahead
                     for j in range(i + 1, len(sorted_notes)):
                         next_start, _, _ = sorted_notes[j]
                         
                         # If next note starts after ours but strictly inside our window -> Overlap
                         if next_start > t and next_start < effective_end:
                             has_space = False
                             break
                         
                         if next_start >= effective_end:
                             break

                is_sustain = is_long_enough and has_space

                if is_sustain:
                    final_dur = max(NOTE_LEN, dur - gap_ticks)
                else:
                    final_dur = NOTE_LEN

                events_buffer.append((final_time, "note_on", gem, 100))
                events_buffer.append((final_time + final_dur, "note_off", gem, 0))

        return sorted(events_buffer, key=lambda x: x[0])

    def _write_track(self, track: MidiTrack, events: List[Tuple[int, str, int, int]]) -> None:
        last_t = 0
        for abs_t, type_, note, vel in events:
            # Calculate delta time relative to the previous event
            delta = max(0, abs_t - last_t)
            track.append(Message(type_, note=note, velocity=vel, time=delta, channel=0))
            last_t = abs_t